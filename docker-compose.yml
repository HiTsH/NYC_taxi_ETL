version: "3"
services:
  mysql:
    image: mysql:5.7
    environment:
      MYSQL_ROOT_PASSWORD: mysql_password_here
    ports:
      - "3306:3306"
    volumes:
      - ./sql/mysql_init.sql:/docker-entrypoint-initdb.d/mysql_init.sql

  postgres:
    image: postgres:13
    environment:
      POSTGRES_PASSWORD: postgres_password_here
    ports:
      - "5432:5432"
    volumes:
      - ./sql/postgres_init.sql:/docker-entrypoint-initdb.d/postgres_init.sql

  zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    ports:
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka:latest
    ports:
      - "9092:9092"
    expose:
      - "9093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  airflow:
    build: ./airflow
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: sqlite:////usr/local/airflow/airflow.db
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/requirements.txt:/requirements.txt
    ports:
      - "8080:8080"
    command: webserver

  airflow_scheduler:
    build: ./airflow
    command: scheduler
    depends_on:
      - airflow

  spark:
    build: ./spark
    environment:
      SPARK_MASTER_NAME: spark-master
      SPARK_MASTER_PORT: 7077
    ports:
      - "8081:8081"

  spark_worker:
    image: bitnami/spark:3.1.2
    environment:
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_MEMORY: 512m
      SPARK_MASTER_URL: spark://spark-master:7077
    depends_on:
      - spark
